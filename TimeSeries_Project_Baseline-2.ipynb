{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTCFI0i81Eqc",
        "outputId": "0477585d-a48c-4f7f-d6ab-ca6e9e96df5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from scipy.stats import kstest\n",
        "from sklearn.metrics import precision_score\n",
        "import scipy\n",
        "from statsmodels.stats.diagnostic import kstest_normal\n",
        "from scipy.stats import norm"
      ],
      "metadata": {
        "id": "K-wIWzXn1fvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load everything\n",
        "NonS = np.loadtxt(\"drive/MyDrive/EEG_recordings/NonS.txt\")\n",
        "PreS = np.loadtxt(\"drive/MyDrive/EEG_recordings/PreS.txt\")\n",
        "Seizure = np.loadtxt(\"drive/MyDrive/EEG_recordings/Seizure.txt\")\n",
        "Test2 = np.loadtxt(\"drive/MyDrive/EEG_recordings/ProjectTestDataSet2.txt\")\n",
        "\n",
        "EEG = np.hstack((NonS, PreS, Seizure))\n",
        "print(EEG.shape)\n",
        "print(PreS.shape)\n",
        "print(NonS.shape)\n",
        "print(Seizure.shape)\n",
        "print(Test2.shape)\n",
        "\n",
        "Test1N = np.loadtxt(\"drive/MyDrive/EEG_recordings/TESTDATASET1.txt\", max_rows=12)\n",
        "Test1P = np.loadtxt(\"drive/MyDrive/EEG_recordings/TESTDATASET1.txt\", skiprows=12, max_rows=12)\n",
        "Test1S = np.loadtxt(\"drive/MyDrive/EEG_recordings/TESTDATASET1.txt\", skiprows=24, max_rows=12)\n",
        "EEG2 = np.hstack((Test1N, Test1P, Test1S))\n",
        "print(EEG2.shape)\n",
        "print([Test1N.shape[1], Test1N.shape[1] + Test1P.shape[1]], EEG2.shape[1])\n",
        "\n",
        "NewTest1 = np.loadtxt(\"drive/MyDrive/EEG_recordings/TestFile1.txt\")\n",
        "NewTest2 = np.loadtxt(\"drive/MyDrive/EEG_recordings/TestFile2.txt\")\n",
        "NewTest3 = np.loadtxt(\"drive/MyDrive/EEG_recordings/TestFile3.txt\")\n",
        "\n",
        "Earth2 = np.loadtxt(\"drive/MyDrive/EEG_recordings/2016.008.01.47.28.IL22.HHZ.txt\")\n",
        "Earth3 = np.loadtxt(\"drive/MyDrive/EEG_recordings/2016.008.01.47.28.IL07.HHZ.txt\")\n",
        "\n",
        "print(\"shapes\")\n",
        "print(NewTest1.shape, NewTest2.shape, NewTest3.shape, Earth2.shape, Earth3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OTtPG2V1igL",
        "outputId": "a0099378-709b-4a40-f90d-af986e7136c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 170752)\n",
            "(12, 76800)\n",
            "(12, 76800)\n",
            "(12, 17152)\n",
            "(9819,)\n",
            "(12, 165760)\n",
            "[76800, 153600] 165760\n",
            "shapes\n",
            "(12, 165760) (12, 38312) (12, 32040) (8782,) (8782,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Baseline algorithm class\n",
        "class BaselineCPD:\n",
        "\n",
        "    #Intializing params\n",
        "    def __init__(self, n0, M, K):\n",
        "\n",
        "        self.n0 = n0\n",
        "        self.M = M\n",
        "        self.K = K\n",
        "        self.AR_params = {}\n",
        "        self.rejection_count = {}\n",
        "        self.f0 = {}\n",
        "\n",
        "    #Function to fit AR model\n",
        "    def fit_model(self, data, max_lags=10):\n",
        "\n",
        "        values = []\n",
        "\n",
        "        for p in range(1, max_lags + 1):\n",
        "\n",
        "            ar_model = AutoReg(data, lags=p, old_names=False).fit()\n",
        "            values.append(ar_model.bic)\n",
        "\n",
        "        best_order = np.argmin(values) + 1\n",
        "\n",
        "        return best_order\n",
        "\n",
        "    #Fitting model after warmup\n",
        "    def warmup(self, data, s):\n",
        "\n",
        "        T = s * self.n0\n",
        "        for c in range(data.shape[0]):\n",
        "\n",
        "            channel_data = data[c][:T]\n",
        "            optimal_lag = self.fit_model(channel_data)\n",
        "            ar_model = AutoReg(channel_data, lags=optimal_lag, old_names=False).fit()\n",
        "\n",
        "            i = ar_model.resid\n",
        "            mean_e = np.mean(i)\n",
        "            std_e = np.std(i)\n",
        "\n",
        "            self.AR_params[c] = {\"model\": ar_model, \"lag\": optimal_lag}\n",
        "            self.f0[c] = norm(mean_e, std_e)\n",
        "            self.rejection_count[c] = 0\n",
        "\n",
        "\n",
        "    #Predict the next window using the AR model and perform hypothesis testing\n",
        "    def predict_and_test(self, data, channel, window_size):\n",
        "\n",
        "        ar_model = self.AR_params[channel][\"model\"]\n",
        "        pred = ar_model.predict(start=len(data), end=len(data) + window_size - 1)\n",
        "        e = data[channel][-window_size:] - pred\n",
        "\n",
        "        return e, self.f0[channel].cdf(e)\n",
        "\n",
        "    #Compute the cumulative divergence between two distributions\n",
        "    def cumulative_divergence(self, e, f1, f0):\n",
        "\n",
        "        divergence = np.sum(np.log(f1.pdf(e) / f0.pdf(e)))\n",
        "        return divergence\n",
        "\n",
        "    #Algorithm to detect CP\n",
        "    def detect_change_point(self, data, s):\n",
        "\n",
        "        cpd_detected = False\n",
        "\n",
        "        for i in range(self.n0 * s, data.shape[1], s):\n",
        "\n",
        "            for c in range(data.shape[0]):\n",
        "\n",
        "                e, cdf_values = self.predict_and_test(data, c, s)\n",
        "                #Using 5-sigma rile\n",
        "                rejected = np.sum(cdf_values) > 125\n",
        "\n",
        "                if rejected:\n",
        "                    cpd_detected = True\n",
        "                    break\n",
        "                else:\n",
        "                    self.rejection_count[c] = 0\n",
        "\n",
        "            if cpd_detected:\n",
        "                break\n",
        "\n",
        "        return cpd_detected"
      ],
      "metadata": {
        "id": "Mj4yHmPr7iIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_change_points(data, baseline_cpd, s):\n",
        "    change_points = []\n",
        "\n",
        "    for i in range(baseline_cpd.n0 * s, len(data[0]), 64 * s):\n",
        "        #Detect if there's a change point\n",
        "        cpd_detected = baseline_cpd.detect_change_point(data[:,:i], s)\n",
        "        if cpd_detected:\n",
        "            #Record the exact position of the change point\n",
        "            change_points.append(i)\n",
        "\n",
        "    return change_points\n",
        "\n",
        "#Compute Average Run Length (ARL) and Expected Detection Delay (EDD) as metrics\n",
        "def compute_arl_edd(detection, ground_truth):\n",
        "    detection_early = []\n",
        "    detection_delays = []\n",
        "\n",
        "    for det_timestamp in detection:\n",
        "        closest_gt = min(ground_truth, key=lambda x: abs(x - det_timestamp))\n",
        "        if det_timestamp < closest_gt:\n",
        "            detection_early.append(closest_gt - det_timestamp)\n",
        "\n",
        "    for gt_timestamp in ground_truth:\n",
        "        closest_det = min(detection, key=lambda x: abs(x - gt_timestamp))\n",
        "        if closest_det > gt_timestamp:\n",
        "            detection_delays.append(closest_det - gt_timestamp)\n",
        "\n",
        "    arl = np.mean(detection_early) if detection_early else 0\n",
        "    edd = np.mean(detection_delays) if detection_delays else 0\n",
        "\n",
        "    return arl, edd"
      ],
      "metadata": {
        "id": "JWXnkolp7pLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial Test Data (EEG)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aqt6pg1aXYpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters: n0 - warmup period length, n1 - window size length, M - rejection threshold, K - cumulative divergence threshold\n",
        "n0 = 60\n",
        "n1 = 64\n",
        "M = 3\n",
        "K = 10\n",
        "s = 128\n",
        "\n",
        "baseline_cpd = BaselineCPD(n0, M, K)\n",
        "\n",
        "#EEG data and ground truth change points\n",
        "gt_bkps = [76800, 76800 * 2, 170752]\n",
        "\n",
        "baseline_cpd.warmup(EEG, s)\n",
        "\n",
        "#Prediction Phase: detect change points\n",
        "predicted_bkps = detect_change_points(EEG, baseline_cpd, s)\n",
        "\n",
        "true_positive = len(set(predicted_bkps).intersection(gt_bkps))\n",
        "precision = true_positive / len(predicted_bkps) if predicted_bkps else 0\n",
        "\n",
        "arl, edd = compute_arl_edd(predicted_bkps[:-1], gt_bkps[:-1])\n",
        "\n",
        "print(f\"Change points prediction: {predicted_bkps}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Average run length (ARL): {arl}\")\n",
        "print(f\"Expected detection delay (EDD): {edd}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIoLinxTXNio",
        "outputId": "cf910d88-3894-4730-bdbe-7e67d251ce56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Change points prediction: [65024, 155136]\n",
            "Precision: 0.0\n",
            "Average run length (ARL): 11776.0\n",
            "Expected detection delay (EDD): 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(EEG[0], label='EEG Data')\n",
        "for gt in gt_bkps:\n",
        "    plt.axvline(x=gt, color='green', linestyle='--', label='Ground Truth CP')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('EEG Signal')\n",
        "plt.title('Ground Truth Change Points')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Visualize EEG data with detected and ground truth change points (Plotting first channel)\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(EEG[0], label='EEG Data')\n",
        "for cp in predicted_bkps:\n",
        "    plt.axvline(x=cp, color='red', linestyle='--', label='Detected CP')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('EEG Signal')\n",
        "plt.title('DetectedChange Points')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SHIgmOaI-nnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test EEG Data"
      ],
      "metadata": {
        "id": "fPRr1wugHxak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters: n0 - warmup period length, n1 - window size length, M - rejection threshold, K - cumulative divergence threshold\n",
        "n0 = 100\n",
        "n1 = 64\n",
        "M = 5\n",
        "K = 10\n",
        "s = 512\n",
        "\n",
        "baseline_cpd = BaselineCPD(n0, M, K)\n",
        "\n",
        "\n",
        "baseline_cpd.warmup(EEG2, s)\n",
        "\n",
        "#Prediction Phase: detect change points\n",
        "predicted_bkps = detect_change_points(EEG2, baseline_cpd, s)\n",
        "\n",
        "\n",
        "print(f\"Change points prediction: {predicted_bkps}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iilfzh6pH4Em",
        "outputId": "e6298f8b-fc0d-4a39-84f4-730715fcf364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Change points prediction: [83968, 116736, 149504]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters: n0 - warmup period length, n1 - window size length, M - rejection threshold, K - cumulative divergence threshold\n",
        "n0 = 80\n",
        "n1 = 64\n",
        "M = 3\n",
        "K = 10\n",
        "s = 512\n",
        "\n",
        "baseline_cpd = BaselineCPD(n0, M, K)\n",
        "\n",
        "\n",
        "baseline_cpd.warmup(NewTest1, s)\n",
        "\n",
        "#Prediction Phase: detect change points\n",
        "predicted_bkps = detect_change_points(NewTest1, baseline_cpd, s)\n",
        "\n",
        "\n",
        "print(f\"Change points prediction: {predicted_bkps}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnSg9-QtK4pw",
        "outputId": "9b3ac101-084b-4528-c230-67cc976469cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Change points prediction: [73728, 106496, 139264]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters: n0 - warmup period length, n1 - window size length, M - rejection threshold, K - cumulative divergence threshold\n",
        "n0 = 80\n",
        "n1 = 64\n",
        "M = 3\n",
        "K = 10\n",
        "s = 128\n",
        "\n",
        "baseline_cpd = BaselineCPD(n0, M, K)\n",
        "\n",
        "\n",
        "baseline_cpd.warmup(NewTest2, s)\n",
        "\n",
        "#Prediction Phase: detect change points\n",
        "predicted_bkps = detect_change_points(NewTest2, baseline_cpd, s)\n",
        "\n",
        "\n",
        "print(f\"Change points prediction: {predicted_bkps}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4N4TJm1LoQd",
        "outputId": "b8742b4a-4209-4fad-e5df-d4906995fa2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Change points prediction: [18432, 26624]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters: n0 - warmup period length, n1 - window size length, M - rejection threshold, K - cumulative divergence threshold\n",
        "n0 = 10\n",
        "n1 = 64\n",
        "M = 3\n",
        "K = 10\n",
        "s = 64\n",
        "\n",
        "baseline_cpd = BaselineCPD(n0, M, K)\n",
        "\n",
        "\n",
        "baseline_cpd.warmup(NewTest3, s)\n",
        "\n",
        "#Prediction Phase: detect change points\n",
        "predicted_bkps = detect_change_points(NewTest3, baseline_cpd, s)\n",
        "\n",
        "\n",
        "print(f\"Change points prediction: {predicted_bkps}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOHsGys_MPxl",
        "outputId": "f9e0c76d-3ddd-4fab-8865-b24a9ea2a858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Change points prediction: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adjusted CPD Implementation for seismic data"
      ],
      "metadata": {
        "id": "AsVw22M-NyaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineCPDEarth:\n",
        "\n",
        "    #Intializing params\n",
        "    def __init__(self, n0, M, K):\n",
        "\n",
        "        self.n0 = n0\n",
        "        self.M = M\n",
        "        self.K = K\n",
        "        self.AR_params = {}\n",
        "        self.rejection_count = 0\n",
        "        self.f0 = {}\n",
        "\n",
        "    #Function to fit AR model\n",
        "    def fit_model(self, data, max_lags=10):\n",
        "\n",
        "        values = []\n",
        "\n",
        "        for p in range(1, max_lags + 1):\n",
        "\n",
        "            ar_model = AutoReg(data, lags=p, old_names=False).fit()\n",
        "            values.append(ar_model.bic)\n",
        "\n",
        "        best_order = np.argmin(values) + 1\n",
        "\n",
        "        return best_order\n",
        "\n",
        "\n",
        "    #Fitting model after warmup\n",
        "    def warmup(self, data, s):\n",
        "\n",
        "        T = s * self.n0\n",
        "        warmup_data = data[:T]\n",
        "\n",
        "        optimal_lag = self.fit_model(warmup_data)\n",
        "        ar_model = AutoReg(warmup_data, lags=optimal_lag, old_names=False).fit()\n",
        "\n",
        "        i = ar_model.resid\n",
        "        mean_e = np.mean(i)\n",
        "        std_e = np.std(i)\n",
        "\n",
        "        self.AR_params = {\"model\": ar_model, \"lag\": optimal_lag}\n",
        "        self.f0 = norm(mean_e, std_e)\n",
        "        self.rejection_count = 0\n",
        "\n",
        "    #Algorithm to detect CP\n",
        "    def detect_change_point(self, data, s):\n",
        "\n",
        "        cpd_detected = False\n",
        "\n",
        "        for i in range(self.n0 * s, len(data), s):\n",
        "            e, cdf_values = self.predict_and_test(data[:i], s)\n",
        "\n",
        "            # Using the 5-sigma rule\n",
        "            rejected = np.sum(cdf_values < 0.05) > self.M\n",
        "\n",
        "            if rejected:\n",
        "                cpd_detected = True\n",
        "                break\n",
        "\n",
        "        return cpd_detected\n",
        "\n",
        "    #Predict the next window using the AR model and perform hypothesis testing\n",
        "    def predict_and_test(self, data, window_size):\n",
        "\n",
        "        ar_model = self.AR_params[\"model\"]\n",
        "        pred = ar_model.predict(start=len(data), end=len(data) + window_size - 1)\n",
        "        e = data[-window_size:] - pred\n",
        "\n",
        "        return e, self.f0.cdf(e)"
      ],
      "metadata": {
        "id": "a3V2mHmGNwMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_change_points(data, baseline_cpd, s):\n",
        "    change_points = []\n",
        "    step_size = s\n",
        "\n",
        "    for i in range(baseline_cpd.n0 * s, len(data), step_size):\n",
        "        cpd_detected = baseline_cpd.detect_change_point(data[:i], s)\n",
        "        if cpd_detected:\n",
        "            change_points.append(i)\n",
        "\n",
        "    return change_points\n"
      ],
      "metadata": {
        "id": "HviLZuATPNDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters: n0 - warmup period length, n1 - window size length, M - rejection threshold, K - cumulative divergence threshold\n",
        "n0 = 10\n",
        "n1 = 64\n",
        "M = 6\n",
        "K = 10\n",
        "s = 100\n",
        "\n",
        "baseline_cpd = BaselineCPDEarth(n0, M, K)\n",
        "\n",
        "\n",
        "baseline_cpd.warmup(Test2, s)\n",
        "\n",
        "#Prediction Phase: detect change points\n",
        "predicted_bkps = detect_change_points(Test2, baseline_cpd, s)\n",
        "\n",
        "\n",
        "print(f\"Change points prediction: {predicted_bkps}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKNLKjdfMusD",
        "outputId": "a47dd9fb-817e-4b82-9ff6-20f4a2f142dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Change points prediction: [1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3300, 3400, 3500, 3600, 3700, 3800, 3900, 4000, 4100, 4200, 4300, 4400, 4500, 4600, 4700, 4800, 4900, 5000, 5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900, 6000, 6100, 6200, 6300, 6400, 6500, 6600, 6700, 6800, 6900, 7000, 7100, 7200, 7300, 7400, 7500, 7600, 7700, 7800, 7900, 8000, 8100, 8200, 8300, 8400, 8500, 8600, 8700, 8800, 8900, 9000, 9100, 9200, 9300, 9400, 9500, 9600, 9700, 9800]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters: n0 - warmup period length, n1 - window size length, M - rejection threshold, K - cumulative divergence threshold\n",
        "n0 = 10\n",
        "n1 = 64\n",
        "M = 6\n",
        "K = 10\n",
        "s = 100\n",
        "\n",
        "baseline_cpd = BaselineCPDEarth(n0, M, K)\n",
        "\n",
        "\n",
        "baseline_cpd.warmup(Earth2, s)\n",
        "\n",
        "#Prediction Phase: detect change points\n",
        "predicted_bkps = detect_change_points(Earth2, baseline_cpd, s)\n",
        "\n",
        "\n",
        "print(f\"Change points prediction: {predicted_bkps}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "difbIrMrQn--",
        "outputId": "ef750366-d419-4f96-e167-8dc0ce6f1467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Change points prediction: [1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3300, 3400, 3500, 3600, 3700, 3800, 3900, 4000, 4100, 4200, 4300, 4400, 4500, 4600, 4700, 4800, 4900, 5000, 5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900, 6000, 6100, 6200, 6300, 6400, 6500, 6600, 6700, 6800, 6900, 7000, 7100, 7200, 7300, 7400, 7500, 7600, 7700, 7800, 7900, 8000, 8100, 8200, 8300, 8400, 8500, 8600, 8700]\n"
          ]
        }
      ]
    }
  ]
}